install_github('recharts', 'taiyun')
install.packages(devtools)
install.packages("devtools")
require(devtools)
install_github('recharts', 'taiyun')
require(recharts)
demo(recharts::recharts)
install.packages("recharts")
countries<-read.table("D:/Work/temp/a.csv",header = F,sep="")
countries
countries<-read.table("D:/Work/temp/a.csv",header = F,sep=",")
countries
install.packages("xgboost")
library(xgboost)
data(agaricus.train)
data(agaricus.test)
train<-agaricus.train
test<-agar3
test<-agaricus.test
head(train)
head(train$data)
head(train$label)
bst <- xgboost(data = train$data, label = train$label, max.depth = 2, eta = 1,
nround = 2, objective = "binary:logistic")
predict(bst,test$data)
dir<-"D:/StudyMaterials/Kaggle/Rossmann Store Sales/"
train_dat<-read.csv(paste0(dir,"train.csv"))
store_dat<-read.csv(paste0(dir,"store.csv"))
test_dat<-read.csv(paste0(dir,"test.csv"))
train<-merge(train_dat,store_dat,by = "Store")
test<-merge(test_dat,store_dat,by = "Store")
head(train)
head(test)
feature.names <- intersect(names(train),names(test))
feature.names
feature.names - c("Date")
feature.names %in% c("Date")
install.packages("mice")
library(mice)
for(i in 1:10)
{row=sample(1:64,1)}
for(i in 1:10){row=sample(1:64,1);col=sample(1:5,1);Insurance[row,col]=NA}
Insurance[1,1]=NA
INS
INS=NA
Insurance=NA
for(i in 1:10){row=sample(1:64,1);col=sample(1:5,1);Insurance[row,col]=NA}
library(MASS)
Iris <- data.frame(rbind(iris3[,,1], iris3[,,2], iris3[,,3]),
Sp = rep(c("s","c","v"), rep(50,3)))
Iris
head(Iris)
train<-sample(1:150,75)
train
table(Iris$Sp[train])
install.packages("knitr")
set.seed(4)
library(randomForest)
data(mtcars)
head(mtcars)
mtcars.rf=randomForest(mpg~,data=mtcars,ntree = 1000,importance = T)
mtcars.rf=randomForest(mpg~.,data=mtcars,ntree = 1000,importance = T)
importance(mtcars.rf)
set.seed(1)
data(iris)
iris.rf=randomForest(Species~.,iris,proximity = T)
MDSplot(iris.rf,iris$Species,palette = rep(1,3),pch=as.numeric(iris$Species))
(1768-1667)/1336
(438-365)/595
90000/1000*2
22*5
296/110
42500/5
81000*0.6
90000*0.35
81000*0.4
12500+10000+8500
90000-42500
x <- c(0, 0, 1, 1, 1, 1)
y <- c(1, 0, 1, 1, 0, 1)
dist(rbind(x, y), method = "binary")
library("AEA")
library("AER")
install.packages("AER")
library("AER")
data(Affairs)
summary(Affairs)
table(Affairs$affairs)
Affairs$ynaffairs[Affairs$affairs>0]<-1
Affairs$ynaffairs[Affairs$affairs==0]<-0
Affairs$ynaffairs<-factor(Affairs$ynaffairs,levels=c(0,1),labels=c("No","Yes"))
table(Affairs$ynaffairs)
fit.full<-glm(ynaffairs<-.,data=Affairs,family=binomial())
library(AER)
data(Affairs)
head(Affairs)
table(Affairs$affairs)
Affairs$ynaffairs[Affairs$affairs>0]<-1
Affairs$ynaffairs[Affairs$affairs==0]<-0
fit.full<-glm(ynaffairs~gender+age+yearsmarried+children+religiousness+education+occupation+rating,data = Affairs,family = binomial())
fit.full
summary(fit.null)
summary(fit.full)
fit.full2<-glm(ynaffairs~age+yearsmarried+religiousness+rating,data = Affairs,family = binomial())
summary(fit.full2)
anova(fit.full,fit.full2,test="Chisq")
dir<-"D:/StudyMaterials/Kaggle/titanic/"
train_dat<-read.csv(paste0(dir,"train.csv"))
test_dat<-read.csv(paste0(dir,"test.csv"))
head(train_dat)
summary(train_dat)
fit.full<-glm(Survived~Pclass+Sex+Age+SibSp+Parch+Ticket+Fare+Embarked,data = trian_dat,family = binomial())
fit.full<-glm(Survived~Pclass+Sex+Age+SibSp+Parch+Ticket+Fare+Embarked,data = train_dat,family = binomial())
fit.full<-glm(Survived~Pclass+Sex+Age+SibSp+Parch+Ticket+Fare,data = train_dat,family = binomial())
summary(fit.ful)
summary(fit.full)
fit.full<-glm(Survived~Pclass+Sex+Age+SibSp+Parch+Fare,data = train_dat,family = binomial())
summary(fit.full)
fit.full2<-glm(Survived~Pclass+Sex+Age+SibSp,data = train_dat,family = binomial())
anova(fit.full,fit.full2,test="Chisq")
summary(fit.full2)
library(psych)
install.packages("psych")
library(psych)
head(USJudgeRatings)
library(psych)
head(USJudgeRatings)
pc<-principal(USJudgeRatings[,-1],nfactors = 1)
pc
fa.parallel(USJudgeRatings[,-1],fa="PC",n.iter = 100)
fa.parallel(USJudgeRatings[,-1],fa="PC",n.iter = 100,show.legend = F)
screeplot(USJudgeRatings[,-1],type="lines")
library(psych)
head(USJudgeRatings)
fa.parallel(USJudgeRatings[,-1],fa="PC",n.iter = 100,show.legend = F)
fa.parallel(USJudgeRatings[,-1],fa="PC",n.iter = 100,show.legend = F,main="")
install.packages("robust")
install.packages("recommenderlab")
library("recommenderlab")
m <- matrix(sample(c(0,1), 50, replace=TRUE), nrow=5, ncol=10,
dimnames=list(users=paste("u", 1:5, sep=''),
items=paste("i", 1:10, sep='')))
install.packages('shiny')
library("shiny")
runApp("d:/work/temp/shinyapp/1")
runApp("d:/work/temp/shinyapp/1")
runExample("01_hello")
runApp("d:/work/temp/shinyapp/1")
runExample("06_tabsets")
runExample("11_timer")
runApp("d:/work/temp/shinyapp/1")
runApp("d:/work/temp/shinyapp/1")
runApp("d:/work/temp/shinyapp/1")
runApp("d:/work/temp/shinyapp/1")
runApp("d:/work/temp/shinyapp/1")
runApp("d:/work/temp/shinyapp/1")
runApp("d:/work/temp/shinyapp/1")
runApp("stockVis")
install.packages("quantmod")
library("quantmod")
runApp("stockVis")
install.packages("RJDBC")
library("rpart")
library("RWeka")
install.packages("RWeka")
library("mvpart")
install.packages("mvpart")
library("mvpart")
head(car)
library("datasets")
car.test.frame
car.test.frame$Mileage<-100*4.546/(1.6*car.test.frame$Mileage)
names(car.test.frame)<-c("价格","产地","可靠性","英里数","类型","车重","发动机功率","净马力")
head(car.test.frame)
str(car.test.frame)
car.test.frame$"水平油耗"<-NA
which(car.test.frame$"油耗">11.6)
car.test.frame$"油耗">11.6
car.test.frame$"油耗"
car.test.frame
head(car.test.frame)
names(car.test.frame)<-c("价格","产地","可靠性","油耗","类型","车重","发动机功率","净马力")
car.test.frame$"油耗">11.6
head(car.test.frame)
names(car.test.frame)<-c("价格","产地","可靠性","油耗","类型","车重","发动机功率","净马力","水平油耗")
car.test.frame$"水平油耗"[which(car.test.frame$"油耗">11.6)]<-"A"
car.test.frame$"水平油耗"[which(car.test.frame$"油耗"<9)]<-"C"
car.test.frame$"水平油耗"[which(car.test.frame$"油耗"==NA)]<-"B"
summary(car.test.frame)
table(car.test.frame$"水平油耗"
)
car.test.frame$"油耗">11.6
sum(car.test.frame$"油耗">11.6)
sum(car.test.frame$"油耗"<9)
car.test.frame$"水平油耗"<-NA
car.test.frame$"水平油耗"[which(car.test.frame$"油耗">11.6)]<-"A"
car.test.frame$"水平油耗"[which(car.test.frame$"油耗"<9)]<-"C"
car.test.frame$"水平油耗"[which(car.test.frame$"水平油耗"==NA)]<-"B"
table(car.test.frame$"水平油耗")
car.test.frame$"水平油耗"==NA
is.na(car.test.frame$"水平油耗")
car.test.frame$"水平油耗"[which(is.na(car.test.frame$"水平油耗"))]<-"B"
table(car.test.frame$"水平油耗")
car.test.frame[1:10,c(4,9)]
table(car.test.frame$"水平油耗")
table(car.test.frame$"水平油耗")/4
round(table(car.test.frame$"水平油耗")/4)
library(sampling)
sub<-strata(car.test.frame,stratanames = "分组油耗",size=(round(table(car.test.frame$"水平油耗")/4)))
sub<-strata(car.test.frame,stratanames = "分组油耗",size=round(table(car.test.frame$"水平油耗")/4))
sub<-strata(car.test.frame,stratanames = "分组油耗",size=c(2,4,9))
sub<-strata(car.test.frame,stratanames = "分组油耗",size=c(2,4,9), method=“srswor"")
sub<-strata(car.test.frame,stratanames = "分组油耗",size=c(2,4,9), method=“srswor")
library(datasets)
car
iris
sub1<-sample(nrow(iris),10,replace = T)
sub1
rep(0,nrow(iris)-1,1)
c(rep(0,nrow(iris)-1,1))
nrow(iris)
rep(0,1)
rep(0,10)
sub2<-sample(nrow(iris),10,replace = T,prob=c(rep(0,nrow(iris)-1),1))
sub2
library(sampling)
library(MASS)
Insurance
head(library(MASS))
head(Insurance)
sub4<-strata(Insurance,stratanames = "District",size = c(1,2,3,4),method = "srswor")
sub4
sub4<-strata(Insurance,stratanames = "District",size = c(1,2,3,4),method = "srswor",description = T)
getdata(Insurance,sub4)
Insurance[sub4,]
sub4
sub6<-strata(Insurance,stratanames = "District",size = c(1,2,3,4),method = "srswor",pik=Insurance$Claims)
sub6
getdata(Insurance,sub6)
sub6<-strata(Insurance,stratanames = "District",size = c(1,2,3,4),method = "systematic",pik=Insurance$Claims)
summary(Insurance)
sub6
getdata(Insurance,sub6)
sub7<-cluster(Insurance,clustername = "District",size = 2,method = "srswor",description = T)
sub7
library("rpart")
data(car.test.frame)
head(car.test.frame)
car.test.frame$Mileage<-100*4.546/(1.6*car.test.frame$Mileage) #将英里数的取值换算为"油耗"指标
names(car.test.frame)<-c("价格","产地","可靠性","油耗","类型","车重","发动机功率","净马力")
head(car.test.frame)
str(car.test.frame)
summary(car.test.frame)
car.test.frame$"水平油耗"<-NA
car.test.frame$"水平油耗"[which(car.test.frame$"油耗">11.6)]<-"A"
car.test.frame$"水平油耗"[which(car.test.frame$"油耗"<9)]<-"C"
car.test.frame$"水平油耗"[which(is.na(car.test.frame$"水平油耗"))]<-"B"
car.test.frame[1:10,c(4,9)]
table(car.test.frame$"水平油耗")
library(sampling)
sub=strata(car.test.frame,size = c(2,4,9),method = "srswor")
sub=strata(car.test.frame,size = c(2,4,9),method = "srswor",stratanames = "水平油耗")
sub
table(car.test.frame$"水平油耗")
table(car.test.frame$"水平油耗")/4
round(table(car.test.frame$"水平油耗")/4)
type(round(table(car.test.frame$"水平油耗")/4))
typeof(round(table(car.test.frame$"水平油耗")/4))
typeof(c(1,2))
sub=strata(car.test.frame,size = round(table(car.test.frame$"水平油耗")/4),method = "srswor",stratanames = "水平油耗")
sub
sub
head(car.test.frame)
order(car.test.frame$"水平油耗")
order(car.test.frame$"水平油耗",decreasing=T)
order(car.test.frame$"水平油耗",decreasing=F)
car.test.frame[order(car.test.frame$"水平油耗",decreasing=F),]
car_order<-car.test.frame[order(car.test.frame$"水平油耗",decreasing=F),]
sub=strata(car_order,size = c(2,4,9),method = "srswor",stratanames = "水平油耗")
sub
train_car<-car.test.frame[-sub$ID_unit,]
nrow(train_car)
test_car<-car.test.frame[sub$ID_unit,]
nrow(test_car)
library(rpart)
head(car.test.frame)
formula_car_reg<-油耗~价格+产地+可靠性+油耗+类型+车重+发动机功率+净马力
rp_car_reg<-rpart(formula_car_reg,data = train_car,method = "anova")
formula_car_reg<-水平油耗~价格+产地+可靠性+油耗+类型+车重+发动机功率+净马力
rp_car_reg<-rpart(formula_car_reg,data = train_car,method = "anova")
print(rp_car_reg)
rp_car_reg
head(car.test.frame)
formula_car_reg<-油耗~价格+产地+可靠性+油耗+类型+车重+发动机功率+净马力
rp_car_reg<-rpart(formula_car_reg,data = train_car,method = "anova")
rp_car_reg
printcp(rp_car_reg)
set.seed(1234)
car_order<-car.test.frame[order(car.test.frame$"水平油耗",decreasing=F),]
sub=strata(car.test.frame,size = c(2,4,9),method = "srswor",stratanames = "水平油耗")
train_car<-car.test.frame[-sub$ID_unit,]
test_car<-car.test.frame[sub$ID_unit,]
formula_car_reg<-水平油耗~价格+产地+可靠性+油耗+类型+车重+发动机功率+净马力  #设定模型公式
rp_car_reg<-rpart(formula_car_reg,data = train_car,method = "anova")  #按照公式对训练集train_car构建回归树
print(rp_car_reg) #导出回归树的cp表格
formula_car_reg<-油耗~价格+产地+可靠性+油耗+类型+车重+发动机功率+净马力  #设定模型公式
rp_car_reg<-rpart(formula_car_reg,data = train_car,method = "anova")  #按照公式对训练集train_car构建回归树
print(rp_car_reg) #导出回归树的cp表格
print(rp_car_reg)
printcp(rp_car_reg)
summary(rp_car_reg)
rp_car_reg<-rpart(formula_car_reg,data = train_car,method = "anova",minsplit=10)
rp_car_reg1<-rpart(formula_car_reg,data = train_car,method = "anova",minsplit=10)
rp_car_reg<-rpart(formula_car_reg,data = train_car,method = "anova")
rp_car_reg1<-rpart(formula_car_reg,data = train_car,method = "anova",minsplit=10)
#将分支包含最小样本数minsplit从默认值20更改为10
print(rp_car_reg1)
printcp(rp_car_reg1)
summary(rp_car_reg1)
rp_car_reg
rp_car_reg1
printcp(rp_car_reg)
printcp(rp_car_reg1)
rp_car_reg2<-rpart(formula_car_reg,data = train_car,method = "anova",cp=0.1)
#将CP值从默认值0.01改为0.1
print(rp_car_reg2)
printcp(rp_car_reg2)
summary(rp_car_reg2)
rp_car_reg3<-prune.rpart(rp_car_reg,cp=0.1)
print(rp_car_reg3)
rp_car_reg4<-rpart(formula_car_reg,data = train_car,method = "anova",maxdepth=1)
rp_car_reg4
rp_car_plot<-rpart(formula_car_reg,data = train_car,method = "anova",minsplit=10)
print(rp_car_plot)
rpart.plot(rp_car_plot)
plot(rp_car_plot)
install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(rp_car_plot)
library(sampling)
install.packages("adabag")
library(adabag)
library("randomForest")
set.seed(4)
data(mtcars)
mtcars_rf<-randomForest(mpg~.,data = mtcars,ntree = 1000,importance = T)
importance(mtcars_rf)
set.seed(1)
data(iris)
iris_rf<-randomForest(Species~.,data = mtcars,ntree = 1000,proximity=T)
head(iris)
iris_rf<-randomForest(Species~.,data = mtcars,ntree = 1000,proximity=T)
iris_rf<-randomForest(Species~.,data = iris,proximity=T)
119/27
101/23
MDSplot(iris_rf,iris$Species,palette = rep(1,3),pch=as.numeric(iris$Species))
data(iris)
iris.na<-iris
iris.na[75,2]<-NA
iris.na[125,3]<-NA
set.seed(111)
iris.imputed<-rfImpute(Species~.,data=iris.na)
list("real"=iris[c(75,125),1:4])
list("real"=iris[c(75,125),1:4],"hava-NA"=iris.na[c(75,125),1:4])
list("real"=iris[c(75,125),1:4],"hava-NA"=iris.na[c(75,125),1:4],"disposed"=iris.imputed[c(75,125),1:4])
list("real"=iris[c(75,125),1:4],"hava-NA"=iris.na[c(75,125),1:4],"disposed"=round(iris.imputed[c(75,125),1:4],1))
round(iris.imputed[c(75,125),2:5],1)
list("real"=iris[c(75,125),1:4],"hava-NA"=iris.na[c(75,125),1:4],"disposed"=round(iris.imputed[c(75,125),2:5],1))
hist（treesize(iris_rf))
hist(treesize(iris_rf))
library(arules)
data(Groceries)
head(Groceries)
summary(Groceries)
inspect(Groceries[1:10])
rules0<-apriori(Groceries,parameter=list(support=0.001,confidence=0.5))
rules0
inspect(rules0[1:10])
rules1<-apriori(Groceries,parameter=list(support=0.005,confidence=0.5)) #120
rules2<-apriori(Groceries,parameter=list(support=0.005,confidence=0.6)) #22
rules3<-apriori(Groceries,parameter=list(support=0.005,confidence=0.64)) #4
inspect(rules3)
rules.sorted_sup<-sort(rules0,by="support")
rules.sorted_sup
rules.sorted_conf<-sort(rules0,by="confidence")
inspect(rules.sorted_conf[1:10])
rules.sorted_lift<-sort(rules0,by="lift")
inpsect(rules.sorted_lift[1:5])
inpspect(rules.sorted_lift[1:5])
inspect(rules.sorted_lift[1:5])
rules4<-apriori(Groceries,parameter=list(support=0.001,confidence=0.1,maxlen=2),appearance=list(rhs="mustard",default="lhs"))
inspect(rules4)
itemsets_apr<-apriori(Groceries,parameter=list(support=0.001,target="frequent itemsets"),control=list(sort=-1))
inspect(itemsets_apr[1:5])
itemsets_ecl<-eclat(Groceries,parameter=list(minlen=1,maxlen=3,support=0.001,target="frequent itemsets"),control=list(sort=-1))
inspect(itemsets_ecl[1:5])
library(arulesViz)
rules5<-apriori(Groceries,parameter=list(support=0.002,confidence=0.5)) #生成关联规则rules5
plot(rules5)
install.packages("arulesViz")
library(arulesViz)
rules5<-apriori(Groceries,parameter=list(support=0.002,confidence=0.5)) #生成关联规则rules5
plot(rules5)
plot(rules5)
plot(rules5,interactive=TRUE)
install.packages("grid")
install.packages("grid")
install.packages("grid")
install.packages("grid")
install.packages("grid")
library(arulesViz)
library(arules)
library(grid)
rules5<-apriori(Groceries,parameter=list(support=0.002,confidence=0.5)) #生成关联规则rules5
plot(rules5)
data(Groceries)
rules5<-apriori(Groceries,parameter=list(support=0.002,confidence=0.5)) #生成关联规则rules5
plot(rules5)
library(arulesViz)
install.packages(c("BH", "boot", "caret", "class", "cluster", "codetools", "curl", "digest", "doParallel", "effects", "foreach", "foreign", "GGally", "ggplot2", "git2r", "h2o", "Hmisc", "httr", "irlba", "iterators", "jsonlite", "kernlab", "KernSmooth", "knitr", "lattice", "manipulate", "MASS", "Matrix", "memoise", "mgcv", "mvtnorm", "nlme", "nnet", "pbkrtest", "R6", "randomForest", "Rcpp", "RcppEigen", "rgl", "rmarkdown", "rpart", "rstudioapi", "spatial", "statmod", "stringi", "survival"))
install.packages(c("BH", "boot", "caret", "class", "cluster",
install.packages(c("BH", "boot", "class"))
setwd("D:/feirie_work/PortableGit/work/read_book/DM_R_IN_ACTION/datasets")
countries<-read.csv("birth.csv",header = F)
dim(countries)
head(countries)
names(countries)<-c("country","birth","death")
countries_rowname<-as.character(countries$country)
for(i in 1:68) row.names(countries)[i]<-countries_rowname[i]
plot(countries$birth,countries$death)
#关注的国家
attention_countries<-c("CHINA","TAIWAN","HONG KONG","INDIA","UNITED STATES","JAPAN")
attention_countries<-c(attention_countries,as.character(countries[which.max(countries$birth),1]))
for(i in 1:length(attention_countries)){
c<-which(countries$country==attention_countries[i])
points(countries[c,-1],pch=16)
legend(countries$birth[c],countries$death[c],as.character(countries[c,1]),bty="n",xjust=0.5,yjust=1,cex=0.8)
}
set.seed(123)
fit_km1<-kmeans(countries[,-1],centers = 3)
print(fit_km1)
#3个类别所含样本数，分布为15，17和36；以及各类别中心点坐标(Cluster means),即第1类可以认为是中等出生率、低死亡率，第2类为低出生率、低死亡率，而第3类为高出生率、高死亡率。从聚类向量(Clustering vector)一栏看到中国大陆及港台都归属于第1类，这之后，软件给出了各类别的组内平方和，1至3类依次升高，即第1类样本点间的差异性最小，第三类最大，且组间平方和占总平方和的81%，该值可用于与类别数取不同值时的聚类结果进行比较，从而找出最优聚类结果，该百分数越大表明组内差距越小、组间差距越大，即聚类效果最好；最后，还可根据获得结果(Available components)部分来分别获取聚类的各项输出结果。
#组间平方和+组内平方和=总平方和
#绘制聚类结果
plot(countries[,-1],pch=(fit_km1$cluster-1))  #将countries数据集中聚为3类的样本点以3种不同形状表示
points(fit_km1$centers,pch=8) #将3类别的中心点以星号标示
legend(fit_km1$centers[1,1],fit_km1$centers[1,2],legend = "Center_1",bty = "n",xjust = 1,yjust = 0,cex = 0.8)
legend(fit_km1$centers[2,1],fit_km1$centers[2,2],legend = "Center_2",bty = "n",xjust = 1,yjust = 0,cex = 0.8)
legend(fit_km1$centers[3,1],fit_km1$centers[3,2],legend = "Center_3",bty = "n",xjust = 1,yjust = 0,cex = 0.8)
#从图中可以看到，中国大陆及港台聚于第1类，即中等出生率、低死亡率，美国、日本和印度都属于低出生率、低死亡率的第2类。
#接下来，我们来调节类别参数center的取值，并通过前面所讨论的组间平方和占总平方和的百分比值(以下简称为“聚类优度”)，来比较选择出最优类别数。
result<-rep(0,67)
for(k in 1:67){
fit_km<-kmeans(countries[,-1],centers = k)
result[k]<-fit_km$betweenss/fit_km$totss
}
round(result,2)
plot(1:67,result,type="b")
plot(1:67,result,type="b",main="choosing theoptimal number of cluster")
plot(1:67,result,type="b",main="choosing theoptimal number of cluster",xlab="number of cluster:1 to 67",ylab="betweenss/totss")
points(10,result[10],pch=16)
legend(10,result[10],paste("(10,",result[10]*100,")",sep=""))
legend(10,result[10],paste("(10,",result[10]*100,")",sep=""),bty="n",xjust=0.3,cex=0.8)
legend(10,result[10],paste("(10,",sprintf("%.1f%%",result[10]*100),")",sep=""),bty="n",xjust=0.3,cex=0.8)
plot(1:67,result,type="b",main="choosing theoptimal number of cluster",xlab="number of cluster:1 to 67",ylab="betweenss/totss") #对result简单制图
points(10,result[10],pch=16) #将类别数为10的点用实心圆标出
legend(10,result[10],paste("(10,",sprintf("%.1f%%",result[10]*100),")",sep=""),bty="n",xjust=0.3,cex=0.8)
fit_km2<-kmeans(countries[,-1],centers = 10)
fit_km2$cluster
fit_km2$cluster=1
fit_km2<-kmeans(countries[,-1],centers = 10)
fit_km2$cluster==1
fit_km2$cluster[which(countries$country=="CHINA")]
cluster_CHINA<-fit_km2$cluster[which(countries$country=="CHINA")]
which(fit_km2$cluster==cluster_CHINA)
library(cluster)
fit_pam<-pam(countries[,-1],3)
print(fit_pam)
fit_km
fit_pam$medoids
which(fit_km$cluster!=fit_pam$clustering)
fit_pam$clustering
which(fit_km$cluster!=fit_pam$cluster)
fit_pam$cluster
print(fit_pam)
fit_km$cluster
fit_km
which(fit_km1$cluster!=fit_pam$cluster)
fit_km1
fit_pam
fit_km1$cluster[1]
fit_km1$cluster==1
cluster_CHINA
which(fit_km1$cluster==1)
which(fit_pam$cluster==1)
which(fit_pam$cluster==1)!=which(fit_km$cluster==1)
which(fit_pam$cluster==1)!=which(fit_km1$cluster==1)
fit_hc<-hclust(dist(countries[,-1]))
print(fit_hc)
dist(countries[,-1])
plot(fit_hc)
group_ke<-cutree(fit_hc,k=3)
group_ke
group_k3<-cutree(fit_hc,k=3)
group_k3
table(group_k3)
group_h18<-cutree(fit_hc,h=18)
group_h18
table(group_h18)
rect.hclust(fit_hc,k=4,border = "light gray")
rect.hclust(fit_hc,k=3,border = "dark gray")
rect.hclust(fit_hc,k=7,which=c(2,6),border = "dark gray")
