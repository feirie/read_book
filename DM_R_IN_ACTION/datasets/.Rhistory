cat("train data column names and details\n")
summary(train)
cat("test data column names and details\n")
summary(test)
train$Date<-as.Date(train$Date)
train[is.na(train)] <- 0
train$month<-as.integer(format(train$Date,"%m"))
train$year<-as.integer(format(train$Date,"%y"))
train$day<-as.integer(format(train$Date,"%d"))
train<-train[which(train$Open==1),]
test$Date<-as.Date(test$Date)
test[is.na(test)] <- 0
test$month<-as.integer(format(test$Date,"%m"))
test$year<-as.integer(format(test$Date,"%y"))
test$day<-as.integer(format(test$Date,"%d"))
head(train)
names(train)
names(test)
intersect(names(train),names(test))
feature.names <- intersect(names(train),names(test))
clf <- randomForest(train[,feature.names],
log(train$Sales+1),
mtry=5,
ntree=50,
sampsize=100,
do.trace=TRUE)
pred <- exp(predict(clf, test)) -1
setdiff(names(test),feature.names)
names(test)
names(train)
head(train[,8])
head(train[,c(3,8)])
dir<-"D:/StudyMaterials/Kaggle/Rossmann Store Sales/"
train_dat<-read.csv(paste0(dir,"train.csv"))
store_dat<-read.csv(paste0(dir,"store.csv"))
test_dat<-read.csv(paste0(dir,"test.csv"))
train<-merge(train_dat,store_dat,by = "Store")
test<-merge(test_dat,store_dat,by = "Store")
cat("train data column names and details\n")
summary(train)
cat("test data column names and details\n")
summary(test)
train$Date<-as.Date(train$Date)
train[is.na(train)] <- 0
train$month<-as.integer(format(train$Date,"%m"))
train$year<-as.integer(format(train$Date,"%y"))
train$day<-as.integer(format(train$Date,"%d"))
train<-train[which(train$Open==1),]
train <- train[,-c(3,8)]
test$Date<-as.Date(test$Date)
test[is.na(test)] <- 0
test$month<-as.integer(format(test$Date,"%m"))
test$year<-as.integer(format(test$Date,"%y"))
test$day<-as.integer(format(test$Date,"%d"))
test <- test[,-c(4,7)]
feature.names <- intersect(names(train),names(test))
clf <- randomForest(train[,feature.names],
log(train$Sales+1),
mtry=5,
ntree=50,
sampsize=100,
do.trace=TRUE)
pred <- exp(predict(clf, test)) -1
pred
submission <- data.frame(Id=test$Id, Sales=pred)
write_csv(submission, paste0(dir,"rf1.csv"))
write.csv(submission, paste0(dir,"rf1.csv"))
write.csv(submission, paste0(dir,"rf1.csv"),col.names=F)
write.csv(submission, paste0(dir,"rf1.csv"),row.names=F)
dir<-"D:/StudyMaterials/Kaggle/Rossmann Store Sales/"
train_dat<-read.csv(paste0(dir,"train.csv"))
store_dat<-read.csv(paste0(dir,"store.csv"))
test_dat<-read.csv(paste0(dir,"test.csv"))
train<-merge(train_dat,store_dat,by = "Store")
test<-merge(test_dat,store_dat,by = "Store")
head(train_dat)
head(train)
head(test)
summary(train)
install.packages(rgl)
install.packages("rgl")
library(rgl)
lines3d(c(0,3,5))
M <- t(M)
shift <- matrix(c(-3, 3, 0), 12, 3, byrow = TRUE)
points3d(M)
lines3d(M + shift)
open3d()
lines3d(c(0,3,5))
points3d(c(0,3,5))
library(rgl)
attach(mtcars)
plot3d(wt, disp, mpg, col="red", size=5)
lines3d(c(0,0,0),c(0,3,5))
lines3d(c(0,0),c(0,3),c(0,5))
character("13323398999 ")
length("13323398999 ")
char("13323398999")
install.packages("kernlab")
library(kernlab)
data(spam)
head(spam)
plot(density(spam$your[spam$type=="nonspam"]),col="blue")
lines(density(spam$your[spam$type=="spam"]),col="red")
abline(v=0.5,col="black")
prediction<-ifelse(spam$your>0.5,"spam","nonspam")
taable(prediction,spam$type)
table(prediction,spam$type)
table(prediction,spam$type)/length(spam$type)
1696543/14681297
66/15
83/19
66/10
1-2^(-53/12)
1-2^(-53/12)*100
1-2^(-53/12)
ls()
dir()
getwd()
require(devtools)
install_github('recharts', 'taiyun')
install.packages(devtools)
install.packages("devtools")
require(devtools)
install_github('recharts', 'taiyun')
require(recharts)
demo(recharts::recharts)
install.packages("recharts")
countries<-read.table("D:/Work/temp/a.csv",header = F,sep="")
countries
countries<-read.table("D:/Work/temp/a.csv",header = F,sep=",")
countries
install.packages("xgboost")
library(xgboost)
data(agaricus.train)
data(agaricus.test)
train<-agaricus.train
test<-agar3
test<-agaricus.test
head(train)
head(train$data)
head(train$label)
bst <- xgboost(data = train$data, label = train$label, max.depth = 2, eta = 1,
nround = 2, objective = "binary:logistic")
predict(bst,test$data)
dir<-"D:/StudyMaterials/Kaggle/Rossmann Store Sales/"
train_dat<-read.csv(paste0(dir,"train.csv"))
store_dat<-read.csv(paste0(dir,"store.csv"))
test_dat<-read.csv(paste0(dir,"test.csv"))
train<-merge(train_dat,store_dat,by = "Store")
test<-merge(test_dat,store_dat,by = "Store")
head(train)
head(test)
feature.names <- intersect(names(train),names(test))
feature.names
feature.names - c("Date")
feature.names %in% c("Date")
install.packages("mice")
library(mice)
for(i in 1:10)
{row=sample(1:64,1)}
for(i in 1:10){row=sample(1:64,1);col=sample(1:5,1);Insurance[row,col]=NA}
Insurance[1,1]=NA
INS
INS=NA
Insurance=NA
for(i in 1:10){row=sample(1:64,1);col=sample(1:5,1);Insurance[row,col]=NA}
library(MASS)
Iris <- data.frame(rbind(iris3[,,1], iris3[,,2], iris3[,,3]),
Sp = rep(c("s","c","v"), rep(50,3)))
Iris
head(Iris)
train<-sample(1:150,75)
train
table(Iris$Sp[train])
install.packages("knitr")
set.seed(4)
library(randomForest)
data(mtcars)
head(mtcars)
mtcars.rf=randomForest(mpg~,data=mtcars,ntree = 1000,importance = T)
mtcars.rf=randomForest(mpg~.,data=mtcars,ntree = 1000,importance = T)
importance(mtcars.rf)
set.seed(1)
data(iris)
iris.rf=randomForest(Species~.,iris,proximity = T)
MDSplot(iris.rf,iris$Species,palette = rep(1,3),pch=as.numeric(iris$Species))
(1768-1667)/1336
(438-365)/595
90000/1000*2
22*5
296/110
42500/5
81000*0.6
90000*0.35
81000*0.4
12500+10000+8500
90000-42500
x <- c(0, 0, 1, 1, 1, 1)
y <- c(1, 0, 1, 1, 0, 1)
dist(rbind(x, y), method = "binary")
library("AEA")
library("AER")
install.packages("AER")
library("AER")
data(Affairs)
summary(Affairs)
table(Affairs$affairs)
Affairs$ynaffairs[Affairs$affairs>0]<-1
Affairs$ynaffairs[Affairs$affairs==0]<-0
Affairs$ynaffairs<-factor(Affairs$ynaffairs,levels=c(0,1),labels=c("No","Yes"))
table(Affairs$ynaffairs)
fit.full<-glm(ynaffairs<-.,data=Affairs,family=binomial())
library(AER)
data(Affairs)
head(Affairs)
table(Affairs$affairs)
Affairs$ynaffairs[Affairs$affairs>0]<-1
Affairs$ynaffairs[Affairs$affairs==0]<-0
fit.full<-glm(ynaffairs~gender+age+yearsmarried+children+religiousness+education+occupation+rating,data = Affairs,family = binomial())
fit.full
summary(fit.null)
summary(fit.full)
fit.full2<-glm(ynaffairs~age+yearsmarried+religiousness+rating,data = Affairs,family = binomial())
summary(fit.full2)
anova(fit.full,fit.full2,test="Chisq")
dir<-"D:/StudyMaterials/Kaggle/titanic/"
train_dat<-read.csv(paste0(dir,"train.csv"))
test_dat<-read.csv(paste0(dir,"test.csv"))
head(train_dat)
summary(train_dat)
fit.full<-glm(Survived~Pclass+Sex+Age+SibSp+Parch+Ticket+Fare+Embarked,data = trian_dat,family = binomial())
fit.full<-glm(Survived~Pclass+Sex+Age+SibSp+Parch+Ticket+Fare+Embarked,data = train_dat,family = binomial())
fit.full<-glm(Survived~Pclass+Sex+Age+SibSp+Parch+Ticket+Fare,data = train_dat,family = binomial())
summary(fit.ful)
summary(fit.full)
fit.full<-glm(Survived~Pclass+Sex+Age+SibSp+Parch+Fare,data = train_dat,family = binomial())
summary(fit.full)
fit.full2<-glm(Survived~Pclass+Sex+Age+SibSp,data = train_dat,family = binomial())
anova(fit.full,fit.full2,test="Chisq")
summary(fit.full2)
library(psych)
install.packages("psych")
library(psych)
head(USJudgeRatings)
library(psych)
head(USJudgeRatings)
pc<-principal(USJudgeRatings[,-1],nfactors = 1)
pc
fa.parallel(USJudgeRatings[,-1],fa="PC",n.iter = 100)
fa.parallel(USJudgeRatings[,-1],fa="PC",n.iter = 100,show.legend = F)
screeplot(USJudgeRatings[,-1],type="lines")
library(psych)
head(USJudgeRatings)
fa.parallel(USJudgeRatings[,-1],fa="PC",n.iter = 100,show.legend = F)
fa.parallel(USJudgeRatings[,-1],fa="PC",n.iter = 100,show.legend = F,main="")
install.packages("robust")
install.packages("recommenderlab")
library("recommenderlab")
m <- matrix(sample(c(0,1), 50, replace=TRUE), nrow=5, ncol=10,
dimnames=list(users=paste("u", 1:5, sep=''),
items=paste("i", 1:10, sep='')))
install.packages('shiny')
library("shiny")
runApp("d:/work/temp/shinyapp/1")
runApp("d:/work/temp/shinyapp/1")
runExample("01_hello")
runApp("d:/work/temp/shinyapp/1")
runExample("06_tabsets")
runExample("11_timer")
runApp("d:/work/temp/shinyapp/1")
runApp("d:/work/temp/shinyapp/1")
runApp("d:/work/temp/shinyapp/1")
runApp("d:/work/temp/shinyapp/1")
runApp("d:/work/temp/shinyapp/1")
runApp("d:/work/temp/shinyapp/1")
runApp("d:/work/temp/shinyapp/1")
runApp("stockVis")
install.packages("quantmod")
library("quantmod")
runApp("stockVis")
install.packages("RJDBC")
library("rpart")
library("RWeka")
install.packages("RWeka")
library("mvpart")
install.packages("mvpart")
library("mvpart")
head(car)
library("datasets")
car.test.frame
car.test.frame$Mileage<-100*4.546/(1.6*car.test.frame$Mileage)
names(car.test.frame)<-c("价格","产地","可靠性","英里数","类型","车重","发动机功率","净马力")
head(car.test.frame)
str(car.test.frame)
car.test.frame$"水平油耗"<-NA
which(car.test.frame$"油耗">11.6)
car.test.frame$"油耗">11.6
car.test.frame$"油耗"
car.test.frame
head(car.test.frame)
names(car.test.frame)<-c("价格","产地","可靠性","油耗","类型","车重","发动机功率","净马力")
car.test.frame$"油耗">11.6
head(car.test.frame)
names(car.test.frame)<-c("价格","产地","可靠性","油耗","类型","车重","发动机功率","净马力","水平油耗")
car.test.frame$"水平油耗"[which(car.test.frame$"油耗">11.6)]<-"A"
car.test.frame$"水平油耗"[which(car.test.frame$"油耗"<9)]<-"C"
car.test.frame$"水平油耗"[which(car.test.frame$"油耗"==NA)]<-"B"
summary(car.test.frame)
table(car.test.frame$"水平油耗"
)
car.test.frame$"油耗">11.6
sum(car.test.frame$"油耗">11.6)
sum(car.test.frame$"油耗"<9)
car.test.frame$"水平油耗"<-NA
car.test.frame$"水平油耗"[which(car.test.frame$"油耗">11.6)]<-"A"
car.test.frame$"水平油耗"[which(car.test.frame$"油耗"<9)]<-"C"
car.test.frame$"水平油耗"[which(car.test.frame$"水平油耗"==NA)]<-"B"
table(car.test.frame$"水平油耗")
car.test.frame$"水平油耗"==NA
is.na(car.test.frame$"水平油耗")
car.test.frame$"水平油耗"[which(is.na(car.test.frame$"水平油耗"))]<-"B"
table(car.test.frame$"水平油耗")
car.test.frame[1:10,c(4,9)]
table(car.test.frame$"水平油耗")
table(car.test.frame$"水平油耗")/4
round(table(car.test.frame$"水平油耗")/4)
library(sampling)
sub<-strata(car.test.frame,stratanames = "分组油耗",size=(round(table(car.test.frame$"水平油耗")/4)))
sub<-strata(car.test.frame,stratanames = "分组油耗",size=round(table(car.test.frame$"水平油耗")/4))
sub<-strata(car.test.frame,stratanames = "分组油耗",size=c(2,4,9))
sub<-strata(car.test.frame,stratanames = "分组油耗",size=c(2,4,9), method=“srswor"")
sub<-strata(car.test.frame,stratanames = "分组油耗",size=c(2,4,9), method=“srswor")
library(datasets)
car
iris
sub1<-sample(nrow(iris),10,replace = T)
sub1
rep(0,nrow(iris)-1,1)
c(rep(0,nrow(iris)-1,1))
nrow(iris)
rep(0,1)
rep(0,10)
sub2<-sample(nrow(iris),10,replace = T,prob=c(rep(0,nrow(iris)-1),1))
sub2
library(sampling)
library(MASS)
Insurance
head(library(MASS))
head(Insurance)
sub4<-strata(Insurance,stratanames = "District",size = c(1,2,3,4),method = "srswor")
sub4
sub4<-strata(Insurance,stratanames = "District",size = c(1,2,3,4),method = "srswor",description = T)
getdata(Insurance,sub4)
Insurance[sub4,]
sub4
sub6<-strata(Insurance,stratanames = "District",size = c(1,2,3,4),method = "srswor",pik=Insurance$Claims)
sub6
getdata(Insurance,sub6)
sub6<-strata(Insurance,stratanames = "District",size = c(1,2,3,4),method = "systematic",pik=Insurance$Claims)
summary(Insurance)
sub6
getdata(Insurance,sub6)
sub7<-cluster(Insurance,clustername = "District",size = 2,method = "srswor",description = T)
sub7
library("rpart")
data(car.test.frame)
head(car.test.frame)
car.test.frame$Mileage<-100*4.546/(1.6*car.test.frame$Mileage) #将英里数的取值换算为"油耗"指标
names(car.test.frame)<-c("价格","产地","可靠性","油耗","类型","车重","发动机功率","净马力")
head(car.test.frame)
str(car.test.frame)
summary(car.test.frame)
car.test.frame$"水平油耗"<-NA
car.test.frame$"水平油耗"[which(car.test.frame$"油耗">11.6)]<-"A"
car.test.frame$"水平油耗"[which(car.test.frame$"油耗"<9)]<-"C"
car.test.frame$"水平油耗"[which(is.na(car.test.frame$"水平油耗"))]<-"B"
car.test.frame[1:10,c(4,9)]
table(car.test.frame$"水平油耗")
library(sampling)
sub=strata(car.test.frame,size = c(2,4,9),method = "srswor")
sub=strata(car.test.frame,size = c(2,4,9),method = "srswor",stratanames = "水平油耗")
sub
table(car.test.frame$"水平油耗")
table(car.test.frame$"水平油耗")/4
round(table(car.test.frame$"水平油耗")/4)
type(round(table(car.test.frame$"水平油耗")/4))
typeof(round(table(car.test.frame$"水平油耗")/4))
typeof(c(1,2))
sub=strata(car.test.frame,size = round(table(car.test.frame$"水平油耗")/4),method = "srswor",stratanames = "水平油耗")
sub
sub
head(car.test.frame)
order(car.test.frame$"水平油耗")
order(car.test.frame$"水平油耗",decreasing=T)
order(car.test.frame$"水平油耗",decreasing=F)
car.test.frame[order(car.test.frame$"水平油耗",decreasing=F),]
car_order<-car.test.frame[order(car.test.frame$"水平油耗",decreasing=F),]
sub=strata(car_order,size = c(2,4,9),method = "srswor",stratanames = "水平油耗")
sub
train_car<-car.test.frame[-sub$ID_unit,]
nrow(train_car)
test_car<-car.test.frame[sub$ID_unit,]
nrow(test_car)
library(rpart)
head(car.test.frame)
formula_car_reg<-油耗~价格+产地+可靠性+油耗+类型+车重+发动机功率+净马力
rp_car_reg<-rpart(formula_car_reg,data = train_car,method = "anova")
formula_car_reg<-水平油耗~价格+产地+可靠性+油耗+类型+车重+发动机功率+净马力
rp_car_reg<-rpart(formula_car_reg,data = train_car,method = "anova")
print(rp_car_reg)
rp_car_reg
head(car.test.frame)
formula_car_reg<-油耗~价格+产地+可靠性+油耗+类型+车重+发动机功率+净马力
rp_car_reg<-rpart(formula_car_reg,data = train_car,method = "anova")
rp_car_reg
printcp(rp_car_reg)
set.seed(1234)
car_order<-car.test.frame[order(car.test.frame$"水平油耗",decreasing=F),]
sub=strata(car.test.frame,size = c(2,4,9),method = "srswor",stratanames = "水平油耗")
train_car<-car.test.frame[-sub$ID_unit,]
test_car<-car.test.frame[sub$ID_unit,]
formula_car_reg<-水平油耗~价格+产地+可靠性+油耗+类型+车重+发动机功率+净马力  #设定模型公式
rp_car_reg<-rpart(formula_car_reg,data = train_car,method = "anova")  #按照公式对训练集train_car构建回归树
print(rp_car_reg) #导出回归树的cp表格
formula_car_reg<-油耗~价格+产地+可靠性+油耗+类型+车重+发动机功率+净马力  #设定模型公式
rp_car_reg<-rpart(formula_car_reg,data = train_car,method = "anova")  #按照公式对训练集train_car构建回归树
print(rp_car_reg) #导出回归树的cp表格
print(rp_car_reg)
printcp(rp_car_reg)
summary(rp_car_reg)
rp_car_reg<-rpart(formula_car_reg,data = train_car,method = "anova",minsplit=10)
rp_car_reg1<-rpart(formula_car_reg,data = train_car,method = "anova",minsplit=10)
rp_car_reg<-rpart(formula_car_reg,data = train_car,method = "anova")
rp_car_reg1<-rpart(formula_car_reg,data = train_car,method = "anova",minsplit=10)
#将分支包含最小样本数minsplit从默认值20更改为10
print(rp_car_reg1)
printcp(rp_car_reg1)
summary(rp_car_reg1)
rp_car_reg
rp_car_reg1
printcp(rp_car_reg)
printcp(rp_car_reg1)
rp_car_reg2<-rpart(formula_car_reg,data = train_car,method = "anova",cp=0.1)
#将CP值从默认值0.01改为0.1
print(rp_car_reg2)
printcp(rp_car_reg2)
summary(rp_car_reg2)
rp_car_reg3<-prune.rpart(rp_car_reg,cp=0.1)
print(rp_car_reg3)
rp_car_reg4<-rpart(formula_car_reg,data = train_car,method = "anova",maxdepth=1)
rp_car_reg4
rp_car_plot<-rpart(formula_car_reg,data = train_car,method = "anova",minsplit=10)
print(rp_car_plot)
rpart.plot(rp_car_plot)
plot(rp_car_plot)
install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(rp_car_plot)
library(sampling)
install.packages("adabag")
library(adabag)
library("adabag")
setwd("D:/feirie_work/PortableGit/work/read_book/DM_R_IN_ACTION/datasets")
data=read.csv("bank.csv",header = T,sep = ";")
head(data)
dim(data)
head(data)
sub=sample(1:nrow(data),round(nrow(data)/4))
head(sub)
length(sub)
nrow(data)
data_train<-data[-sub,]
data_test<-data[sub,]
library(adabag)
library(rpart)
bag<-bagging(y~.,data_train,mfinal = 5)
names(bag)
bag$trees
names(bag)
bag$votes
names(bag)
head(data_train$prob)
head(bag$prob)
head(bag$votes)
head(bag$class)
head(bag$samples)
names(bag)
bag$importance
bag$importance
bag$terms
bag$trees[2]
bag1<-bagging(y~.,data_train,mfinal = 5,control=rpart.control(maxdepth=3))
bag1$trees[2]
pre_bag<-predict(bag,data_test)
head(pre_bag)
names(pre_bag)
pre_bag$error
pre_bag$confusion
err_bag<-sum(pre_bag$class!=data_test$y)/nrow(data_test)
err_bag
sub_minor<-which(data_test$y=="yes")
sub_minor
sub_major<-which(data_test$y=="no") #取no类在测试集中的编号
err_minor_bag<-sum(pre_bag$class[sub_minor]!=data_test$y[sub_minor])/nrow(data_test)
err_minor_bag
err_major_bag<-sum(pre_bag$class[sub_major]!=data_test$y[sub_major])/nrow(data_test)  #计算yes类的错误率
err_major_bag
err_minor_bag<-sum(pre_bag$class[sub_minor]!=data_test$y[sub_minor])/length(sub_minor)
err_minor_bag
err_major_bag<-sum(pre_bag$class[sub_major]!=data_test$y[sub_major])/length(sub_major)
err_major_bag
